import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import KFold  # For K-fold cross-validation
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
# Load the dataset
data = pd.read_csv("D:\\East_data.csv")

X = np.array(data.iloc[:, :-1])
y = np.array(data.iloc[:, -1])

# Standardize the data
scaler = StandardScaler()

# Standardize the features (pixel values)
X = scaler.fit_transform(X)

# Reshape to original shape
X = X.reshape(data.shape[0], 65, 65, 1)

# Focal Loss Implementation
def focal_loss(gamma=2., alpha=0.25):
    """
    Focal Loss for binary classification.
    Args:
    gamma (float): Focusing parameter, default is 2.
    alpha (float): Balance factor, default is 0.25.
    """
    def focal_loss_fixed(y_true, y_pred):
        # Clip predictions to prevent log(0)
        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())

        # Compute cross entropy loss
        cross_entropy_loss = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)

        # Compute modulating factor (1 - p_t)^gamma
        modulating_factor = tf.pow(1 - y_pred, gamma)

        # Apply focal loss formula
        loss = alpha * modulating_factor * cross_entropy_loss

        return tf.reduce_sum(loss, axis=-1)

    return focal_loss_fixed

# Create an empty list to store results for each fold
results = []

# Define KFold cross-validation
kf = KFold(n_splits=5, shuffle=False)  # 5-fold cross-validation

# Loop through each fold
for fold, (train_val_idx, test_idx) in enumerate(kf.split(X), 1):
    print(f"Training for fold {fold}...")

    # Split the data into training+validation and test sets
    X_train_val, X_test = X[train_val_idx], X[test_idx]
    y_train_val, y_test = y[train_val_idx], y[test_idx]

    # Further split the training+validation set into 7:1 for training and validation
    split_index = int(0.875 * len(X_train_val))  # 87.5% of the data for training (7:8 ratio)
    X_train, X_val = X_train_val[:split_index], X_train_val[split_index:]
    y_train, y_val = y_train_val[:split_index], y_train_val[split_index:]

    # Build the Convolutional Neural Network model
    model = Sequential()

    # First convolutional layer
    model.add(Conv2D(8, kernel_size=(3, 3), strides=(2, 2), activation='relu', input_shape=(65, 65, 1)))
    model.add(BatchNormalization())
    model.add(Dropout(0.1))

    # Second convolutional layer
    model.add(Conv2D(16, kernel_size=(3, 3), strides=(2, 2), activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.1))

    # Third convolutional layer
    model.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.1))

    # Global average pooling layer
    model.add(GlobalAveragePooling2D())

    # Fully connected layers
    model.add(Dense(50, activation='relu'))
    model.add(Dense(10, activation='relu'))

    # Output layer
    model.add(Dense(1, activation='sigmoid'))

    new_optimizer = Adam(learning_rate=0.001)
    model.compile(loss=focal_loss(gamma=2., alpha=0.25), optimizer=new_optimizer, metrics=['accuracy'])
    print(model.summary())

    # Fit the model
    history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=2, validation_data=(X_val, y_val))

    # Plot accuracy curves during training
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Evaluate the model
    y_pred = model.predict(X_test)  # Predict on the test set
    y_pred_binary = np.round(y_pred).astype(int)  # Round predictions to 0 or 1 for binary classification

    # Calculate performance metrics
    accuracy = accuracy_score(y_test, y_pred_binary)  # Accuracy
    precision = precision_score(y_test, y_pred_binary)  # Precision
    recall = recall_score(y_test, y_pred_binary)  # Recall
    f1 = f1_score(y_test, y_pred_binary)  # F1 score

    # Compute ROC curve and AUC
    fpr, tpr, _ = roc_curve(y_test, y_pred)  # False positive rate and true positive rate
    roc_auc = auc(fpr, tpr)  # Area under the ROC curve

    # Compute confusion matrix
    conf_matrix = confusion_matrix(y_test, y_pred_binary)  # Confusion matrix
    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])  # Sensitivity

    # Print the evaluation metrics for the current fold
    print(f"Fold {fold} - Accuracy:", accuracy)
    print(f"Fold {fold} - Precision:", precision)
    print(f"Fold {fold} - Recall:", recall)
    print(f"Fold {fold} - F1 Score:", f1)
    print(f"Fold {fold} - AUC:", roc_auc)
    print(f"Fold {fold} - Sensitivity:", sensitivity)
    print(f"Fold {fold} - Specificity:", specificity)
    print(f"Fold {fold} - Confusion Matrix:\n", conf_matrix)

    # Store the metrics in a dictionary
    result_dict = {
        'Fold': fold,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity,
        'Conf_matrix': conf_matrix
    }

    # Append the result to the list
    results.append(result_dict)

# Convert the results to a DataFrame
results_df = pd.DataFrame(results)

# Export the results to an Excel file
results_df.to_excel("D:\\L-diameter_cross_validation_results.xlsx", index=False)

print("Evaluation results have been saved to 'L-diameter_cross_validation_results.xlsx'.")
